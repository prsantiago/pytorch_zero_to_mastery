{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. What are 3 areas on industry where computer vision is currently being used?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Streaming services\n",
    "2. Social network services\n",
    "3. Image generation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Search \"what is overfitting in machine learning?\" and write down a sentence about what you find."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting occurs when a model is excessively complex and has too many parameters relative to the size of the training data. As a result, the model may fit the training data very well, but it may no generalize well to new, unseen data. This means that the model will perform poorly on tasks it has not seen before, even though it may have a high accuracy on the training data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Search \"ways to prevent overfitting in machine learning\" write down 3 of the things you find and a sentence about each."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Use cross-validation: Instead of splitting your data into a fixed training and testing set, you can use cross-validation to evaluate your model. This involves dividing your data into \"folds\", training on some folds, and evaluating on the remaining folds. You can then average the performance across all folds to get a better estimate of your model's generalization performance.\n",
    "2. Ensemble methods: One way to reduce overfitting is to train multiple models and combine their predictions. This can be done by averaging the predictions of multiple models, or by training a higher-level model to make use of the predictions of multiple lower-level models.\n",
    "3. Reducing the complexity of the model: A model with too many parameters may be prone to overefitting. One way to prevent this is to use a simpler model with fewer parameters, or to use techniques like feature selection to remove unnecessary features from the model."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Spend 20-minutes reading and clicking through the CNN Eplainer website"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. load the ```torchvision.datasets.MNIST``` train and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = MNIST(\n",
    "    root='data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = MNIST(\n",
    "    root='data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualize at leat 5 different samples of the MNIST training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "row=1\n",
    "column=5\n",
    "for i in range(5):\n",
    "    image, label = train_data[i]\n",
    "    plt.subplot(row,column,i+1)\n",
    "    plt.title(label)\n",
    "    plt.axis(False)\n",
    "    plt.imshow(image.squeeze(), cmap='gray')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Turn the MNIST train and test datasets into dataloaders using ```torch.utils.data.DataLoader```, set the ```batch_size=32```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Recreate model_2 used in this notebook capable of fitting on the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv_stack_1 = nn.Sequential(\n",
    "            nn.Conv2d(input_shape, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.conv_stack_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(hidden_units*7*7, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_stack_1(x)\n",
    "        x = self.conv_stack_2(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Train the model you built in exercise 8 on CPU and GPU and see how long it takes on each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper_functions import train_step, test_step, print_train_time, eval_model\n",
    "from timeit import default_timer as timer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinyvgg_cpu = TinyVGG(1, 10, len(train_data.classes)).to('cpu')\n",
    "tinyvgg_gpu = TinyVGG(1, 10, len(train_data.classes)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import Accuracy\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(tinyvgg_gpu.parameters(), lr=0.1)\n",
    "acc_fn_gpu = Accuracy('multiclass', num_classes=len(train_data.classes)).to(device)\n",
    "acc_fn_cpu = Accuracy('multiclass', num_classes=len(train_data.classes)).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 3\n",
    "train_start_gpu = timer()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}-----')\n",
    "    train_step(tinyvgg_gpu, train_dataloader, loss_fn, optimizer, acc_fn_gpu, device)\n",
    "    test_step(tinyvgg_gpu, test_dataloader, loss_fn, acc_fn_gpu, device)\n",
    "\n",
    "train_end_gpu = timer()\n",
    "total_train_time = print_train_time(train_start_gpu, train_end_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "epochs = 3\n",
    "train_start_cpu = timer()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}-----')\n",
    "    train_step(tinyvgg_cpu, train_dataloader, loss_fn, optimizer, acc_fn_cpu, 'cpu')\n",
    "    test_step(tinyvgg_cpu, test_dataloader, loss_fn, acc_fn_cpu, 'cpu')\n",
    "\n",
    "train_end_cpu = timer()\n",
    "total_train_time = print_train_time(train_start_cpu, train_end_cpu, 'cpu')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Make predictions using your trained model and visualize at least 5 of them comparing the prediction to the target label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinyvgg_cpu_results = eval_model(tinyvgg_cpu, test_dataloader, loss_fn, acc_fn_cpu, 'cpu')\n",
    "tinyvgg_gpu_results = eval_model(tinyvgg_gpu, test_dataloader, loss_fn, acc_fn_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tinyvgg_cpu_results, tinyvgg_gpu_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "X, y = next(iter(test_dataloader))\n",
    "X, y = X.to(device), y.to(device)\n",
    "\n",
    "pred_labels = None\n",
    "\n",
    "tinyvgg_gpu.eval()\n",
    "with torch.inference_mode():\n",
    "    pred_logits = tinyvgg_gpu(X)\n",
    "    pred_labels = pred_logits.argmax(dim=1)\n",
    "\n",
    "X, y = X.cpu(), y.cpu()\n",
    "\n",
    "for i in range(5):\n",
    "    plt.subplot(1,5,i+1)\n",
    "    plt.imshow(X[i].squeeze())\n",
    "    plt.title(f'{pred_labels[i]} == {y[i]}')    \n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Plot confusion matrix comparing your model's predictions to the truth labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "torch.manual_seed(42)\n",
    "\n",
    "tinyvgg_gpu.eval()\n",
    "preds_label = []\n",
    "with torch.inference_mode():\n",
    "    for X, y in test_dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        preds_logits = tinyvgg_gpu(X)\n",
    "        preds_label.append(preds_logits.argmax(dim=1).cpu())\n",
    "\n",
    "pred_tensor = torch.concat(preds_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confmat = ConfusionMatrix('multiclass', num_classes=len(test_data.classes))\n",
    "confmat_tensor = confmat(preds=pred_tensor, target=test_data.targets)\n",
    "\n",
    "fig, ax = plot_confusion_matrix(confmat_tensor.numpy(), class_names=test_data.classes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Create a random tensor of shape [1,3,64,64] and pass it through a ```nn.Conv2d()``` layer with various hyperparameter settings (these can be any settings you choose), what do you notice if the ```kernel_size``` parameter goes up and down?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand((1,3,64,64))\n",
    "\n",
    "kernel_1 = nn.Conv2d(3, 10, 1, 1, 0)\n",
    "kernel_3 = nn.Conv2d(3, 10, 3, 1, 0)\n",
    "kernel_5 = nn.Conv2d(3, 10, 5, 1, 0)\n",
    "kernel_7 = nn.Conv2d(3, 10, 7, 1, 0)\n",
    "\n",
    "out1 = kernel_1(random_tensor)\n",
    "out3 = kernel_3(random_tensor)\n",
    "out5 = kernel_5(random_tensor)\n",
    "out7 = kernel_7(random_tensor)\n",
    "\n",
    "out1.shape, out3.shape, out5.shape, out7.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Use a model similar to the trained ```model_2``` from this notebook to make predictions on the test ```torchvision.datasets.FashionMNIST``` dataset.\n",
    "- Then plot some predictions where the model was wrong alongside what the label of the image should've been.\n",
    "- After visualizing these predictions do you think it's more of a modelling error or a data error?\n",
    "- As in, could the model do better or are the labels of the data too close to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiteacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645d004dd1412f554783dad564b4ed89d297d59ce6765071e5ea4608253deff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
