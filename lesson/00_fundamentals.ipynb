{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To represent scalar and vector, use lowercase letters.\n",
    "\n",
    "\n",
    "To represent MATRIX and TENSOR, use uppercase letters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a torch-scalar\n",
    "scalar = torch.tensor(7)\n",
    "scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the dimensions of a tensor\n",
    "scalar.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve torch value as an integer (only works with one-element tensors)\n",
    "scalar.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector, a single dimension tensor that can have many numbers\n",
    "vector = torch.tensor([7,7])\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the number of dimensions of vector \n",
    "# (tip: ndim = number of '[' on the tensor)\n",
    "vector.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of vector\n",
    "# how the elements inside them are arranged\n",
    "vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix \n",
    "# matrix.ndim > vector.ndim\n",
    "MATRIX = torch.tensor([[7,8], [9,10]])\n",
    "MATRIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check number of dimensions\n",
    "MATRIX.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MATRIX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor, can represent almost anything (images, words, etc)\n",
    "# e.g.\n",
    "#   day of week = [1,2,3]\n",
    "#   steak sales = [4,5,6]\n",
    "#   almond butter sales = [7,8,9]\n",
    "TENSOR = torch.tensor([[[1,2,3], [4,5,6], [7,8,9]]])\n",
    "TENSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of dimensions for TENSOR\n",
    "TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check shape of TENSOR\n",
    "TENSOR.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a machine learning often starts out with large random tensors of numbers and adjusts these random number as it works through data to better represent it.\n",
    "\n",
    "Workflow:\n",
    "- Start with random numbers\n",
    "- Look at data\n",
    "- Update random numbers\n",
    "- Look at data\n",
    "- Update random numbers\n",
    "- ...\n",
    "\n",
    "As a data scientist, you define how the model:\n",
    "- starts (initialization)\n",
    "- looks at data (representation)\n",
    "- updates (optimization) its random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random tensor of size (3,4)\n",
    "random_tensor = torch.rand(size=(3,4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random tensor of size (224, 224, 3)\n",
    "random_image_size_tensor = torch.rand(size=(224,224,3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeros and ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tensors are usually use for masking (masking some of the values in one tensor with zeros to let a model know not to learn them)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3,4))\n",
    "zeros, zeros.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3,4))\n",
    "ones, ones.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a range and tensors like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use torch.arange(), torch.range() is deprecated\n",
    "zero_to_ten_deprecated = torch.range(0,10)\n",
    "print(zero_to_ten_deprecated)\n",
    "\n",
    "# Create a range of values 0 to 10\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also create a tensor of zeros similar to another tensor (same shape)\n",
    "ten_zeros = torch.zeros_like(input=zero_to_ten)\n",
    "print(ten_zeros)\n",
    "\n",
    "ten_ones = torch.ones_like(input=zero_to_ten)\n",
    "ten_ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor([3.0,6.0,9.0],\n",
    "                                dtype=None, # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "                                device=None,  # defaults to None, which uses the default tensor type\n",
    "                                requires_grad=False # if enabled, operations performed on the tensor are recorded\n",
    ")\n",
    "\n",
    "float_32_tensor.ndim, float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from shape issues, datatype and device issues are also common.\n",
    "\n",
    "- one of tensors is torch.float32 and the other is torch.float16 -> ERROR\n",
    "- one of your tensors is on the CPU and the other is on the GPU -> ERROR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor with float16 datatype\n",
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                                dtype=torch.float16) # torch.half would also work\n",
    "\n",
    "float_16_tensor.dtype                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting information from tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when an error messages show up, recall:\n",
    "\n",
    "\"what shape are my tensors? what datatype are they and where are they stored? what shape, what datatype, where where where\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "some_tensor = torch.rand(size=[2,1,3])\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f'shape of tensor: {some_tensor.shape}')\n",
    "print(f'datatype of tensor: {some_tensor.dtype}')\n",
    "print(f'device tensor is stored on: {some_tensor.device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manipulating tensors (tensor operations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic operations on tensors:\n",
    "- Addition\n",
    "- Substraction\n",
    "- Multiplication (element-wise)\n",
    "- Division\n",
    "- Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor of values and add a number to it\n",
    "tensor = torch.tensor([1,2,3])\n",
    "tensor + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply it by 10\n",
    "tensor * 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensors don't change unless reassigned\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subtrack adn reassign\n",
    "tensor -= 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add and reassign\n",
    "tensor += 10\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use torch funtions\n",
    "print(torch.add(tensor,10))\n",
    "print(torch.subtract(tensor,10))\n",
    "print(torch.mul(tensor,10))\n",
    "\n",
    "# Original tensor is still unchanged\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise multiplication\n",
    "print(tensor, \"*\", tensor)\n",
    "print(tensor*tensor)\n",
    "print(torch.mul(tensor, tensor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"@\" is the symbol for matrix multiplication\n",
    "\n",
    "Operation: (n x m) @ (m x p) = (n x p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1,2,3])\n",
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Element-wise matrix multiplication\n",
    "# [1*1, 2*2, 3*3]\n",
    "tensor * tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrix multiplication\n",
    "# [1*1 + 2*2 + 3*3]\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use the \"@\" symbol for matrix multiplication, though not recommended\n",
    "tensor @ tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Matrix multiplication by hand\n",
    "# Avoid doing operations with for loops at all cost, they are computationally expensive\n",
    "value=0\n",
    "for i in range(len(tensor)):\n",
    "    value += tensor[i] * tensor[i]\n",
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "## Matrix multiplication by in-built function\n",
    "torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Common errors in deep learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the most common errors in DL is shape mismatches\n",
    "tensor_A = torch.tensor([[1,2], [3,4], [5,6]], dtype=torch.float32)\n",
    "tensor_B = torch.tensor([[7,8], [9,10], [11,12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be arranged with a transpose (switch the dimensions of a given tensor)\n",
    "\n",
    "# view tensor_A and tensor_B\n",
    "print(tensor_A)\n",
    "print(tensor_B)\n",
    "\n",
    "# view tensor_A and tensor_B.T\n",
    "print(tensor_A)\n",
    "print(tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The opearion works when tensor_B is transposed\n",
    "print(f'Original shapes: tensor_A = {tensor_A.shape}, tensor_B = {tensor_B.shape}\\n')\n",
    "print(f'New shapes: tensor_A = {tensor_A.shape} (same), tensor_B.T = {tensor_B.T.shape}\\n')\n",
    "print(f'Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n')\n",
    "print(f'Output:\\n')\n",
    "output = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(output)\n",
    "print(f'\\nOutput shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.mm is a shorcut for matmul\n",
    "torch.mm(tensor_A, tensor_B.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the linear layer starts with a random weights matrix, let's make it reproducible (more on this later)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=2, # in features = matches inner dimension of input\n",
    "                        out_features=6 #  out_features = describes outer value\n",
    "                        )\n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x)\n",
    "print(f'Input shape: {x.shape}\\n')\n",
    "print(f'Output:\\n{output}\\n\\nOutput shape: {output.shape}')\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using x with its transpose\n",
    "# This uses matrix multiplication\n",
    "linear = torch.nn.Linear(in_features=3, # in features = matches inner dimension of input\n",
    "                        out_features=6 #  out_features = describes outer value\n",
    "                        )\n",
    "\n",
    "x = tensor_A\n",
    "output = linear(x.T)\n",
    "print(f'Input shape: {x.shape}\\n')\n",
    "print(f'Output:\\n{output}\\n\\nOutput shape: {output.shape}')\n",
    "print(linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the min, max, mean, sum, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(0, 100, 10)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Minimum: {x.min()}')\n",
    "print(f'Maximum: {x.max()}')\n",
    "# print(f'Mean: {x.mean()}') # this will error\n",
    "print(f'Mean: {x.type(torch.float32).mean()}') # won't work without float datatype\n",
    "print(f'Sum: {x.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same but with torch methods\n",
    "torch.max(x), torch.min(x), torch.mean(x.type(torch.float32)), torch.sum(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional min/max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f'Tensor: {tensor}')\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f'Index where max value occurs: {tensor.argmax()}')\n",
    "print(f'Index where min value occurs: {tensor.argmin()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional tensor datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor and check its datatype\n",
    "tensor = torch.arange(10.0, 100.0, 10.0)\n",
    "tensor, tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a float16 version\n",
    "tensor_float16 = tensor.type(torch.float16)\n",
    "tensor_float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a int8 tensor\n",
    "tensor_int8 = tensor.type(torch.int8)\n",
    "tensor_int8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping, stacking, squeezing and unsqueezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1., 8.)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an extra dimension\n",
    "x_reshaped = x.reshape(1,7)\n",
    "x_reshaped_ = torch.reshape(x, (1,7))\n",
    "print(x_reshaped, x_reshaped.shape)\n",
    "print(x_reshaped_, x_reshaped_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change view (keeps same data as original but changes view)\n",
    "z = x.view(1,7)\n",
    "z, z.shape, x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing a view-created tensor also changes the original\n",
    "print(x)\n",
    "z[:, 0] = 5\n",
    "print(z)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# Changing a reshape-created tensor also changes the original\n",
    "print(x)\n",
    "x_reshaped[:, 1] = 5\n",
    "print(x_reshaped)\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "# Changing a reshape-created tensor also changes the original\n",
    "print(x)\n",
    "x_reshaped_[:, 2] = 5\n",
    "print(x_reshaped_)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack tensors on top of each other\n",
    "x_stacked_0 = torch.stack([x,x,x,x], dim=0)\n",
    "x_stacked_1 = torch.stack([x,x,x,x], dim=1)\n",
    "\n",
    "x_stacked_0, x_stacked_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Previous tensor: {x_reshaped}')\n",
    "print(f'Previous shape: {x_reshaped.shape}')\n",
    "\n",
    "# Remove extra dimension from x_reshaped\n",
    "x_squeezed = x_reshaped.squeeze()\n",
    "x_squeezed_ = torch.squeeze(x_reshaped)\n",
    "print(f'Squeeze tensor: {x_squeezed_}')\n",
    "print(f'Squeeze shape: {x_squeezed_.shape}')\n",
    "print(f'Squeeze tensor: {x_squeezed_}')\n",
    "print(f'Squeeze shape: {x_squeezed_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Previous tensor: {x_squeezed}')\n",
    "print(f'Previous shape: {x_squeezed.shape}')\n",
    "\n",
    "# Add an extra dimension with unsqueeze\n",
    "x_unsqueezed = x_squeezed.unsqueeze(dim=0)\n",
    "x_unsqueezed_ = torch.unsqueeze(x_squeezed, 0)\n",
    "print(f'Unsqueezed tensor: {x_unsqueezed}')\n",
    "print(f'Unsqueezed shape: {x_unsqueezed.shape}')\n",
    "\n",
    "print(f'Unsqueezed tensor: {x_unsqueezed_}')\n",
    "print(f'Unsqueezed shape: {x_unsqueezed_.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor with specific shape\n",
    "x_original = torch.rand(size=(224,224,3))\n",
    "\n",
    "# Permute the original tensor to rearrange the axis order\n",
    "x_permuted = x_original.permute(2,0,1) # shifts axis 0->1, 1->2, 2->0\n",
    "x_permuted_ = torch.permute(x_original, (2,0,1))\n",
    "\n",
    "print(f'Previous shape: {x_original.shape}')\n",
    "print(f'New shape: {x_permuted.shape}')\n",
    "print(f'New shape: {x_permuted_.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor\n",
    "x = torch.arange(1, 10).reshape(1,3,3)\n",
    "x, x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's index bracket by bracker\n",
    "print(f'First square bracket:\\n{x[0]}')\n",
    "print(f'Second square bracket:\\n{x[0][0]}')\n",
    "print(f'Third square bracket:\\n{x[0][0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of 0th dimension and the 0 index of 1st dimension\n",
    "x[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of 0th & 1st dimensions but only index 1 of 2nd dimension\n",
    "x[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all values of the 0 dimension but only the 1 index value of the 1st and 2nd dimension\n",
    "x[:, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get index 0 of 0th and 1st dimension and all values of 2nd dimension\n",
    "x[0, 0, :] # same as x[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch tensors & NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NumPy array to tensor\n",
    "import numpy as np\n",
    "\n",
    "array = np.arange(1.0, 8.0)\n",
    "tensor = torch.from_numpy(array) # defaults to np.array type\n",
    "tensor_32 = torch.from_numpy(array).type(torch.float32)\n",
    "array, tensor, tensor_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the array, keep the tensor and viceversa\n",
    "array = array + 1\n",
    "tensor = tensor + 2\n",
    "array, tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor to NumPy array\n",
    "tensor = torch.ones(7) # create a tensor of ones with dtype=float32\n",
    "numpy_tensor = tensor.numpy() # will be dtype=float32 unless changed\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the tensor, keep the array the same\n",
    "tensor = tensor + 1\n",
    "numpy_tensor = numpy_tensor + 2\n",
    "tensor, numpy_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two random tensors\n",
    "random_tensor_A = torch.rand(3, 4)\n",
    "random_tensor_B = torch.rand(3, 4)\n",
    "\n",
    "print(f'Tensor A:\\n{random_tensor_A}\\n')\n",
    "print(f'Tensor B:\\n{random_tensor_B}\\n')\n",
    "print(f'Does Tensor A equal Tensor B? (anywhere)')\n",
    "random_tensor_A == random_tensor_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "## Set the random seed\n",
    "RANDOM_SEED = 41 # try changing this to different values and see what happens to the numbers below\n",
    "torch.manual_seed(seed=RANDOM_SEED)\n",
    "random_tensor_C = torch.rand(3, 4)\n",
    "\n",
    "# Have to reset the seed every time a new rand() is called\n",
    "# Without this, tensor_D would be different to tensor_C\n",
    "torch.random.manual_seed(seed=RANDOM_SEED) # try commenting this line out and seeing what happens\n",
    "random_tensor_D = torch.rand(3,4)\n",
    "\n",
    "# WIth the manual reset of the seed\n",
    "random_tensor_E = torch.rand(3,4)\n",
    "\n",
    "print(f'Tensor C:\\n{random_tensor_C}')\n",
    "print(f'Tensor D:\\n{random_tensor_D}')\n",
    "print(f'Tensor E:\\n{random_tensor_E}')\n",
    "print()\n",
    "\n",
    "print(f'Does Tensor C equal Tensor D (anywhere)')\n",
    "print(random_tensor_C == random_tensor_D)\n",
    "print(f'Does Tensor C equal Tensor E (anywhere)')\n",
    "print(random_tensor_C == random_tensor_E)\n",
    "print(f'Does Tensor D equal Tensor E (anywhere)')\n",
    "print(random_tensor_D == random_tensor_E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running tensors on GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting PyTorch to run on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device type\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of devices\n",
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting tensors on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tensor (defualt on CPU)\n",
    "tensor = torch.tensor([1,2,3])\n",
    "\n",
    "# Tensor not on GPU\n",
    "print(tensor, tensor.device)\n",
    "\n",
    "# Move tensor to GPU (if available), and reassign it\n",
    "tensor_on_gpu = tensor.to(device)\n",
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tensor_on_gpu, tensor)\n",
    "tensor = tensor + 1\n",
    "\n",
    "print(tensor_on_gpu, tensor)\n",
    "tensor_on_gpu = tensor_on_gpu + 2\n",
    "\n",
    "tensor_on_gpu, tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moving tensors back to the CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If tensor is on GPU, can't transform it to NumPy (this will error)\n",
    "tensor_on_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instead, copy the tensor back to cpu\n",
    "tensor_back_on_cpu = tensor_on_gpu.cpu().numpy()\n",
    "tensor_back_on_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_on_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aiteacher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645d004dd1412f554783dad564b4ed89d297d59ce6765071e5ea4608253deff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
