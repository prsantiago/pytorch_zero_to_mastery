{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Computer vision libraries in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import PyTorch\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "# Import torchvision \n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Import matplotlib for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Check versions\n",
    "# Note: your PyTorch version shouldn't be lower than 1.10.0 and torchvision version shouldn't be lower than 0.11\n",
    "print(f\"PyTorch version: {torch.__version__}\\ntorchvision version: {torchvision.__version__}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Getting a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training data\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root='data', # where to download data to?\n",
    "    train=True, # get training data\n",
    "    download=True, # download data if it doesn't exist on disk\n",
    "    transform=ToTensor(), # iamges come as PIL format, we want to turn into Torch tensors\n",
    "    target_transform=None # you can transform labels as well\n",
    ")\n",
    "\n",
    "# Setup testing data\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    train=False, \n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See first training sample\n",
    "image, label = train_data[0]\n",
    "image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Input and output shapes of a computer vision model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What's the shape of the image?\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many samples are there?\n",
    "len(train_data.data), len(train_data.targets), len(test_data.data), len(test_data.targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See classes\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Visualizing our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('image shape',image.shape)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(image.squeeze()) # image shape is [1, 28, 28]\n",
    "plt.title(label)\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(image.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot more images\n",
    "torch.manual_seed(42)\n",
    "fig = plt.figure(figsize=(9,9))\n",
    "rows, cols = 4,4 \n",
    "for i in range(1, rows*cols + 1):\n",
    "    random_idx = torch.randint(0, len(train_data), size=[1]).item()\n",
    "    img, label = train_data[random_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(img.squeeze(), cmap='gray')\n",
    "    plt.title(class_names[label])\n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup the batch size hyperparameter\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Turn datasets into iterables (batches)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data, # dataset to turn into iterable\n",
    "    batch_size=BATCH_SIZE, # how many samples per batch?\n",
    "    shuffle=True, # shuffle data every epoch?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # don't necessarily have to shuffle the testing data\n",
    ")\n",
    "\n",
    "# Let's check out what we've created\n",
    "print(f\"Dataloaders: {train_dataloader, test_dataloader}\") \n",
    "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of test dataloader: {len(test_dataloader)} batches of {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out what's inside the training dataloader\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "train_features_batch.shape, train_labels_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show a sample\n",
    "torch.manual_seed(42)\n",
    "random_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[random_idx], train_labels_batch[random_idx]\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.title(class_names[label])\n",
    "plt.axis(\"Off\")\n",
    "\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label: {label}, label size: {label.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model 0: Build a baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a flatten layer\n",
    "flatten_model = nn.Flatten() # all nn modules function as a model (can do a forward pass)\n",
    "\n",
    "# Get a single sample\n",
    "x = train_features_batch[0]\n",
    "\n",
    "# Flatten the sample\n",
    "output = flatten_model(x) # perform forward pass\n",
    "\n",
    "# Print out what happened\n",
    "print(f\"Shape before flattening: {x.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Shape after flattening: {output.shape} -> [color_channels, height*width]\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class FashionMNISTModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(), # neural networks like their inputs in vector form\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(hidden_units, output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layer_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Need to setup model with input parameters\n",
    "model_0 = FashionMNISTModelV0(\n",
    "    input_shape=784, # one for every pixel (28x28)\n",
    "    hidden_units=10, # how many units in the hidden layer\n",
    "    output_shape=len(class_names) # one for every class\n",
    ")\n",
    "\n",
    "model_0.to(\"cpu\") # keep model on CPU to begin with"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Setup loss, optimizer and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import accuracy metric\n",
    "import torchmetrics\n",
    "\n",
    "# Setup loss function and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss() # this is also called 'criterion'/'cost_function' in some places\n",
    "acc_fn = torchmetrics.Accuracy(task='multiclass', num_classes=len(class_names)).to('cpu') \n",
    "optimizer = torch.optim.SGD(model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Creating a function to time our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "\n",
    "def print_train_time(start: float, end: float, device: torch.device = None):\n",
    "    \"\"\" Prints difference between start and end time.\n",
    "\n",
    "    Args:\n",
    "        start (float): Start time of computation (preferred in timeit format).\n",
    "        end (float): End time of computation.\n",
    "        device ([type], optional): Device that compute is running on. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        float: time between start and end in seconds (higher is longer).\n",
    "    \"\"\"\n",
    "    total_time = end - start\n",
    "    print(f'Train time on {device}: {total_time:.3f} seconds')\n",
    "    return total_time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Creating a training loop and training a model on batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set the seed and start the timer\n",
    "torch.manual_seed(42)\n",
    "train_time_start_on_cpu = timer()\n",
    "\n",
    "# Set the number of epochs (we'll keep this small for faster training times)\n",
    "epochs = 3\n",
    "\n",
    "# Create training and testing loop\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}\\n...')\n",
    "    ### Training\n",
    "    train_loss = 0\n",
    "    # Add a loop to loop through training batches\n",
    "    # for batch, (X, y) in enumerate(train_dataloader):\n",
    "    for X, y in train_dataloader:\n",
    "        model_0.train()\n",
    "\n",
    "        # 1. Forward pass\n",
    "        train_pred = model_0(X)\n",
    "\n",
    "        # 2. Calculate loss (per batch)\n",
    "        batch_train_loss = loss_fn(train_pred, y)\n",
    "        train_loss += batch_train_loss # accumulatively add up the loss per epoch\n",
    "\n",
    "        # 3. Optimzer zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # 4. Loss backward\n",
    "        batch_train_loss.backward()\n",
    "\n",
    "        # 5. Optim zero\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print out how many samples have been seen (optional)\n",
    "        # if batch % 400 == 0:\n",
    "        #     print(f'Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples')\n",
    "\n",
    "    # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    ### Testing\n",
    "    # Setup variables for accumulatively adding up loss and accuracy\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in test_dataloader:\n",
    "            # 1. Forward pass\n",
    "            test_pred = model_0(X)\n",
    "\n",
    "            # 2. Calculate loss (accumulatively)\n",
    "            test_loss += loss_fn(test_pred, y) # accumulatively add up the loss per epoch\n",
    "\n",
    "            # 3. Calculate accuracy (preds need to be same as y_true)\n",
    "            test_acc += acc_fn(y, test_pred.argmax(dim=1))\n",
    "\n",
    "        # Calculations on test metrics need to happen inside torch.inference_mode()\n",
    "        # Divide total test loss by length of test dataloader (per batch)\n",
    "        test_loss /= len(test_dataloader)\n",
    "\n",
    "        # Divide total accuracy by length of test dataloader (per batch)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    ## Print out what's happening\n",
    "    print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}, Test acc: {test_acc:.2f}\\n\")\n",
    "\n",
    "# Calculate training time\n",
    "train_time_end_on_cpu = timer()\n",
    "total_train_time_model_0 = print_train_time(train_time_start_on_cpu, train_time_end_on_cpu, str(next(model_0.parameters()).device))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Make predictions and get Model 0 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "def eval_model(model: torch.nn.Module, data_loader: torch.utils.data.DataLoader, loss_fn: torch.nn.Module, acc_fn: torchmetrics.Accuracy, device: torch.device):\n",
    "    \"\"\" Returns a dictionary containing the results of model predicting on data_loader\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A PyTorch model capable of making predictions on data_loader.\n",
    "        data_loader (torch.utils.data.DataLoader): The target dataset to predict on.\n",
    "        loss_fn (torch.nn.Module): The loss function of model.\n",
    "        acc_fn (torchmetrics.Accuracy): An accuracy function to campare the models predictions to the truth labels.\n",
    "        device (str, optional): Target device to compute on. Defaults to device.\n",
    "\n",
    "    Returns:\n",
    "        dict: Results of model making predictions on data_loader\n",
    "    \"\"\"\n",
    "    loss, acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in data_loader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            preds = model(X)\n",
    "\n",
    "            loss += loss_fn(preds, y)\n",
    "            acc += acc_fn(preds.argmax(dim=1), y) # fo accuracy, need the predictions label\n",
    "\n",
    "        loss /= len(data_loader)\n",
    "        acc /= len(data_loader)\n",
    "\n",
    "    return {\n",
    "        \"model_name\": model.__class__.__name__, # only works when model was created with a class\n",
    "        \"model_loss\": loss.item(),\n",
    "        \"model_acc\": acc.item()\n",
    "    }\n",
    "\n",
    "# Calculate model 0 results on test dataset\n",
    "model_0_results = eval_model(model_0, test_dataloader, loss_fn, acc_fn, 'cpu')\n",
    "\n",
    "model_0_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Setup device agnostic-code (for using a GPU if there is one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device agnostic code\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Model 1: Building a better model with non-linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model with non-linear and linear layers\n",
    "class FashionMNISTModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.stack_layers = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_shape, hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_units, output_shape),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return self.stack_layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_1 = FashionMNISTModelV1(\n",
    "    784,    # number of input features\n",
    "    10,\n",
    "    10      # number of output classes desired\n",
    ").to(device)\n",
    "\n",
    "model_1, next(model_1.parameters()).device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Setup loss, optimizer, and evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.1)\n",
    "acc_fn = torchmetrics.Accuracy(task='multiclass', num_classes=len(class_names)).to(device) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Functionizing training and test loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model: torch.nn.Module,\n",
    "               dataloader: torch.utils.data.DataLoader,\n",
    "               loss_fn: torch.nn.Module,\n",
    "               optimizer: torch.optim.Optimizer,\n",
    "               acc_fn: torchmetrics.Metric,\n",
    "               device: torch.device = device):\n",
    "    train_loss, train_acc = 0,0 \n",
    "    model.train()\n",
    "    \n",
    "    for X, y in dataloader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        \n",
    "        pred = model(X)\n",
    "\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss\n",
    "        train_acc += acc_fn(y, pred.argmax(dim=1)) \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Calculate loss and accuracy per epoch and print out what's happening\n",
    "    train_loss /= len(dataloader)\n",
    "    train_acc /= len(dataloader)\n",
    "    print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.4f}\")\n",
    "\n",
    "def test_step(model: torch.nn.Module,\n",
    "                dataloader: torch.utils.data.DataLoader,\n",
    "                loss_fn: torch.nn.Module,\n",
    "                acc_fn: torchmetrics.Metric,\n",
    "                device: torch.device = device):\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += loss_fn(pred, y)\n",
    "            test_acc += acc_fn(y, pred.argmax(dim=1))\n",
    "\n",
    "        # Calculate loss and accuracy per epoch and print out what's happening\n",
    "        test_loss /= len(dataloader)\n",
    "        test_acc /= len(dataloader)\n",
    "        print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.4f}\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as timer\n",
    "train_time_start_on_gpu = timer()\n",
    "\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch: {epoch}\\n-----\")\n",
    "    train_step(model_1, train_dataloader, loss_fn, optimizer, acc_fn, device)\n",
    "    test_step(model_1, test_dataloader, loss_fn, acc_fn, device)\n",
    "\n",
    "train_time_end_on_gpu = timer()\n",
    "total_train_time_model_1 = print_train_time(train_time_start_on_gpu, train_time_end_on_gpu, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Note: This will error due to 'eval_model()' not using device agnostic code\n",
    "model_1_results = eval_model(model_1, test_dataloader, loss_fn, acc_fn, device)\n",
    "model_1_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Model 2: Building a Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a convolutional neural network\n",
    "class FashionMNISTModelV2(nn.Module):\n",
    "    \"\"\"Model architecture copying TinyVGG from:\n",
    "    https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
    "        super().__init__()\n",
    "        self.block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3, # how big is the square that's going over the image\n",
    "                      stride=1, # default\n",
    "                      padding=1 # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units,\n",
    "                      out_channels=hidden_units,\n",
    "                      kernel_size=3,\n",
    "                      stride=1,\n",
    "                      padding=1\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # default stride value is same as kernel_size\n",
    "        )\n",
    "        self.block_2 = nn.Sequential(\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(hidden_units, hidden_units, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # Where did this in_features shape come from=\n",
    "            # It's because each of our network compresses and changes the shape of our input data\n",
    "            nn.Linear(in_features=hidden_units*7*7,\n",
    "                      out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.classifier(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "model_2 = FashionMNISTModelV2(1, 10, len(class_names)).to(device)\n",
    "model_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Stepping through ```nn.Conv2d()```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create sample batch of random numbers with same size as image batch\n",
    "images = torch.randn(size=(32, 3, 64, 64)) # [batch_size, color_channels, height, width]\n",
    "test_image = images[0] # get a single image for testing\n",
    "print(f\"Image batch shape: {images.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Single image shape: {test_image.shape} -> [color_channels, height, width]\") \n",
    "print(f\"Single image pixel values:\\n{test_image}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a convolutional layer with the same dimensions as TinyVGG\n",
    "# (try changing any of the parameters and see what happens)\n",
    "conv_layer = nn.Conv2d(in_channels=3,\n",
    "                       out_channels=10,\n",
    "                       kernel_size=3,\n",
    "                       stride=1,\n",
    "                       padding=0) # also try using \"valid\" or \"same\" here\n",
    "\n",
    "# Pass the data through the convolutional layer\n",
    "conv_layer(test_image) # Note: If running PyTorch < 1.11.0, this will error because of shape issues (nn.Conv2d() expects a 4d tensor as input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra dimension to test image\n",
    "test_image.shape, test_image.unsqueeze(dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass test image with extra dimension through conv_layer\n",
    "conv_layer(test_image.unsqueeze(dim=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a new conv_layer with different values (try setting these to whatever you like)\n",
    "conv_layer_2 = nn.Conv2d(in_channels=3, # same number of color channels as our input image\n",
    "                         out_channels=10,\n",
    "                         kernel_size=5, # kernel is usually a square so a tuple also works\n",
    "                         stride=2,\n",
    "                         padding=0)\n",
    "\n",
    "# Pass single image through new conv_layer_2 (this calls nn.Conv2d()'s forward() method on the input)\n",
    "conv_layer_2(test_image.unsqueeze(dim=0)).shape                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the conv_layer_2 internal parameters\n",
    "print(conv_layer_2.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shapes of weight and bias tensors within conv_layer_2\n",
    "print(f\"conv_layer_2 weight shape: \\n{conv_layer_2.weight.shape} -> [out_channels={conv_layer_2.weight.shape[0]}, in_channels={conv_layer_2.weight.shape[1]}, kernel_size={conv_layer_2.weight.shape[2]}, kernel_size={conv_layer_2.weight.shape[3]}]\")\n",
    "print(f\"\\nconv_layer_2 bias shape: \\n{conv_layer_2.bias.shape} -> [out_channels={conv_layer_2.bias.shape[0]}]\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Stepping through ```nn.MaxPool2d```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out original image shape without and with unsqueezed dimension\n",
    "print(f\"Test image original shape: {test_image.shape}\")\n",
    "print(f\"Test image with unsqueezed dimension: {test_image.unsqueeze(dim=0).shape}\")\n",
    "\n",
    "# Create a sample nn.MaxPool2d() layer\n",
    "max_pool_layer = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "# Pass data through just the conv_layer\n",
    "test_image_through_conv = conv_layer(test_image.unsqueeze(dim=0))\n",
    "print(f\"Shape after going through conv_layer(): {test_image_through_conv.shape}\")\n",
    "\n",
    "# Pass data through the max pool layer\n",
    "test_image_through_conv_and_max_pool = max_pool_layer(test_image_through_conv)\n",
    "print(f\"Shape after going through conv_layer() and max_pool_layer(): {test_image_through_conv_and_max_pool.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Create a random tensor with a similar number of dimensions to out images\n",
    "random_tensor = torch.randn(size=(1,1,2,2))\n",
    "print(f\"Random tensor:\\n{random_tensor}\")\n",
    "print(f\"Random tensor shape: {random_tensor.shape}\")\n",
    "\n",
    "# Create a max pool layer\n",
    "max_pool_layer = nn.MaxPool2d(2) # see what happens when you change the kernel_size values\n",
    "\n",
    "# Pass the random tensor through the max pool layer\n",
    "max_pool_tensor = max_pool_layer(random_tensor)\n",
    "print(f\"\\nMax pool tensor:\\n{max_pool_tensor} <- this is the maximum value from random_tensor\")\n",
    "print(f\"Max pool tensor shape: {max_pool_tensor.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Setup a loss function and optimizer for ```model_2```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup loss and optimizer\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.1)\n",
    "acc_fn = torchmetrics.Accuracy(task='multiclass', num_classes=len(class_names)).to(device) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4 Training and testing model_2 using our train and test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "# Measure time\n",
    "from timeit import default_timer as Timer\n",
    "\n",
    "train_time_start_model_2 = timer()\n",
    "\n",
    "# Train and test model\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    print(f'Epoch: {epoch}\\n-----')\n",
    "    train_step(model_2, train_dataloader, loss_fn, optimizer, acc_fn, device)\n",
    "    test_step(model_2, test_dataloader, loss_fn, acc_fn, device)\n",
    "\n",
    "train_time_end_model_2 = timer()\n",
    "total_train_time_model_2 = print_train_time(train_time_start_model_2, train_time_end_model_2, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model_2 results\n",
    "model_2_results = eval_model(model_2, test_dataloader, loss_fn, acc_fn, device)\n",
    "model_2_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Compare model results and training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "compare_results = pd.DataFrame([model_0_results, model_1_results, model_2_results])\n",
    "compare_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training times to results comparison\n",
    "compare_results[\"training_time\"] = [total_train_time_model_0, total_train_time_model_1, total_train_time_model_2]\n",
    "compare_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Performance-speed tradeoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize our model results\n",
    "compare_results.set_index(\"model_name\")[\"model_acc\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"accuracy (%)\")\n",
    "plt.ylabel(\"model\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Make and evaluate random predictions with best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(model: torch.nn.Module, data: list, device: torch.device = device):\n",
    "    pred_probs = []\n",
    "    model.eval()\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for sample in data:\n",
    "            # Prepare sample\n",
    "            sample = torch.unsqueeze(sample, dim=0).to(device) # Add an extra dimension and send sample to device\n",
    "\n",
    "            # Forward pass (model outputs raw logits)\n",
    "            pred_logits = model(sample)\n",
    "\n",
    "            # Get prediction probability (logit -> prediction probability)\n",
    "            pred_prob = torch.softmax(pred_logits.squeeze(), dim=0)\n",
    "\n",
    "            # Get pred_prob off GPU for further calculations\n",
    "            pred_probs.append(pred_prob.cpu())\n",
    "\n",
    "    # Stack the pred_probs to turn list into a tensor\n",
    "    return torch.stack(pred_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_data), k=9):\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "# View the first test sample shape and label\n",
    "print(f\"Test sample image shape: {test_samples[0].shape}\\nTest sample label: {test_labels[0]} ({class_names[test_labels[0]]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on test samples with model 2\n",
    "pred_probs = make_predictions(model_2, test_samples)\n",
    "\n",
    "# View first two prediction probabilities list\n",
    "pred_probs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the prediction probabilities into prediction labels by taking the argmax()\n",
    "pred_classes = pred_probs.argmax(dim=1)\n",
    "pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels, pred_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot predictions\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "nrows=3\n",
    "ncols=3\n",
    "\n",
    "for i, sample in enumerate(test_samples):\n",
    "    # Create a subplot\n",
    "    plt.subplot(nrows, ncols, i+1)\n",
    "\n",
    "    # Plot the target image\n",
    "    plt.imshow(sample.squeeze(), cmap=\"gray\")\n",
    "\n",
    "    # Find the prediction label (in text form, e.g. \"Sandal\")\n",
    "    pred_label = class_names[pred_classes[i]]\n",
    "\n",
    "    # Get the truth label (in text form, e.g. \"T-shirt\")\n",
    "    truth_label = class_names[test_labels[i]]\n",
    "\n",
    "    # Create the title text of the plot\n",
    "    title_text = f'Pred: {pred_label} | Truth: {truth_label}'\n",
    "\n",
    "    # Check for equality and change title colour accordingly\n",
    "    if pred_label == truth_label:\n",
    "        plt.title(title_text, fontsize=10, c=\"g\",) # green text if correct\n",
    "    else:\n",
    "        plt.title(title_text, fontsize=10, c=\"r\") # red text if wrong\n",
    "    \n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Making a confusion matrix for further prediction evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tqdm for progress bar\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# 1. Make predictions with trained model\n",
    "preds = []\n",
    "model_2.eval()\n",
    "\n",
    "with torch.inference_mode():\n",
    "    for X, y in tqdm(test_dataloader, desc=\"Making predictions\"):\n",
    "        # Send data and targets to target device\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Do the forward pass\n",
    "        pred_logit = model_2(X)\n",
    "\n",
    "        # Turn predictins from logits -> prediction probabilities -> predicitions labels\n",
    "        pred = torch.softmax(pred_logit, dim=1).argmax(dim=1)\n",
    "\n",
    "        # Put predictions on CPU for evaluation\n",
    "        preds.append(pred.cpu())\n",
    "\n",
    "# Concatenates list of predicitons into a tensor\n",
    "pred_tensor = torch.cat(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See if torchmetrics exists, if not, install it\n",
    "try:\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")\n",
    "    assert int(mlxtend.__version__.split(\".\")[1]) >= 19, \"mlxtend verison should be 0.19.0 or higher\"\n",
    "except:\n",
    "    !pip install -q torchmetrics -U mlxtend # <- Note: If you're using Google Colab, this may require restarting the runtime\n",
    "    import torchmetrics, mlxtend\n",
    "    print(f\"mlxtend version: {mlxtend.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion matrix instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(num_classes=len(class_names), task=\"multiclass\")\n",
    "confmat_tensor = confmat(preds=pred_tensor, target=test_data.targets)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib llikes working with numpy\n",
    "    class_names=class_names, # turn the row and colum labels into class names\n",
    "    figsize=(10,7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Save and load best performing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Create model sdirectory (if it doesn't already exist)\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, # create parent directories if needed\n",
    "                 exist_ok=True # if models directory already exists, don´t error\n",
    ")\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"fashionmnist_model_2.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# Save the model state dict\n",
    "print(f'Saving model to: {MODEL_SAVE_PATH}')\n",
    "torch.save(obj=model_2.state_dict(), # state_dict() only saves the learned parameters\n",
    "           f=MODEL_SAVE_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of FashionMNISTModelV2 (the same class as our saved state_dict())\n",
    "# Note: loading model will error if the shapes here aren´t the same as the saved version\n",
    "loaded_model_2 = FashionMNISTModelV2(input_shape=1,\n",
    "                                     hidden_units=10, # try changing this to 128 and seeing what happens\n",
    "                                     output_shape=10)\n",
    "\n",
    "# Load in the saved state_dict()\n",
    "loaded_model_2.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n",
    "\n",
    "# Send model to GPU\n",
    "loaded_model_2 = loaded_model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded model\n",
    "torch.manual_seed(42)\n",
    "\n",
    "loaded_model_2_results = eval_model(\n",
    "    model=loaded_model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    acc_fn=acc_fn,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "loaded_model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if results are close to each other (if they are very far away, there may be an error)\n",
    "torch.isclose(torch.tensor(model_2_results[\"model_loss\"]),\n",
    "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
    "              rtol=0.0001, # relative tolerance\n",
    "              atol=1e-08              \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiteacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645d004dd1412f554783dad564b4ed89d297d59ce6765071e5ea4608253deff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
