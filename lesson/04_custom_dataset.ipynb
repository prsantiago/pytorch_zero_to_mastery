{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Importing PyTorch and setting up device-agnostic code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup device-agnostic node\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn´t exist, download it and prepare it...\n",
    "if image_path.is_dir():\n",
    "    print(f'{image_path} directory exists.')\n",
    "else:\n",
    "    print(f'Did not find {image_path} directory, creating one...')\n",
    "    image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Download pizza, steak, sushi data\n",
    "    with open(data_path/\"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "        request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "        print(\"Downloading data...\")\n",
    "        f.write(request.content)\n",
    "\n",
    "    # Unzip pizza, steak, sushi data\n",
    "    with zipfile.ZipFile(data_path/\"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "        print(\"Unzipping data...\")\n",
    "        zip_ref.extractall(image_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Become one with the data (data preparation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"\n",
    "    Walks through dir_path returning its contents.\n",
    "    Args:\n",
    "        dir_path (str or pathlib.Path): target directory\n",
    "\n",
    "    Returns:\n",
    "        A print out of:\n",
    "            number of subdirectories in dir_path\n",
    "            number of images (files) in each subdirectory\n",
    "            name of each subdirectory\n",
    "    \"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\"\n",
    "\n",
    "train_dir, test_dir"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualize an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set seed\n",
    "random.seed(42) # <- try changing this and see what happens\n",
    "\n",
    "# 1. Get all image paths (* means \"any combination\")\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# 2. Get random iamge path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# 3. Get image class from path name (the image class is the name of the directory where the image is store)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "# 4. Open image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. Print metadata\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn the image into an aray\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels]\")\n",
    "plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Transforming data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Transforming data with ```torchvision.transforms```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write transforms for image\n",
    "data_transform = transforms.Compose([\n",
    "    # Resize the images to 64 x 64\n",
    "    transforms.Resize(size=(64,64)),\n",
    "    # Flip the images randomly on the horizontal\n",
    "    transforms.RandomHorizontalFlip(p=0.5), # p = probability of flip, 0.5 = 50% chance\n",
    "    # Turn the iamge into a torch.Tensor\n",
    "    transforms.ToTensor() # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths, transform, n=3, seed=42):\n",
    "    \"\"\"Plots a series of random images from image_paths\n",
    "\n",
    "    Will open n image paths from iamge_paths, transform them\n",
    "    with transform and plot them side by side.\n",
    "    \n",
    "    Args:\n",
    "        image_path (list): List of target image paths.\n",
    "        transform (PyTorch Trnasforms): Transforms to apply to images.\n",
    "        n (int, optional): Number of images to plot. Defaults to 3.\n",
    "        seed (int, optional): Random seed for the random generator. Defaults to 42.\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(seed)\n",
    "    random_image_paths = random.sample(image_paths, k=n)\n",
    "    for image_path in random_image_paths:\n",
    "        with Image.open(image_path) as f:\n",
    "            fig, ax = plt.subplots(1,2)\n",
    "            ax[0].imshow(f)\n",
    "            ax[0].set_title(f\"Original \\nSize: {f.size}\")\n",
    "            ax[0].axis(False)\n",
    "\n",
    "            # Transform and plot image\n",
    "            # Note: permute() will change shape of image to suit matplotlib\n",
    "            # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
    "            transformed_image = transform(f).permute(1,2,0)\n",
    "            ax[1].imshow(transformed_image)\n",
    "            ax[1].set_title(f\"Transformed \\nSize: {transformed_image.shape}\")\n",
    "            ax[1].axis(False)\n",
    "\n",
    "            fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_path_list, transform=data_transform, n=3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Option 1: Loading Image Data Using `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(root=train_dir, # target folder of images\n",
    "                                  transform=data_transform, # transforms to perform on data (images)\n",
    "                                  target_transform=None # transforms to perform on labels (if necessary)\n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(root=test_dir,\n",
    "                                 transform=data_transform)\n",
    "\n",
    "print(f\"Train data:\\n{train_data}\\nTest data:\\n{test_data}\")                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as a list\n",
    "class_names = train_data.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also get class names as a dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the lengths\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n{img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rearrange the order of dimensions\n",
    "img_permute = img.permute(1,2,0)\n",
    "\n",
    "# Print out different shapes (before and after permute)\n",
    "print(f\"Original shape: {img.shape} -> [color_channels, height, width]\")\n",
    "print(f\"Image permute shape: {img_permute.shape} -> [height, width, color_channels]\")\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(10,7))\n",
    "plt.imshow(img.permute(1,2,0))\n",
    "plt.axis(False)\n",
    "plt.title(class_names[label], fontsize=14)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1 Turn loaded images into `DataLoader`'s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the number of CPUs\n",
    "import os\n",
    "\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn train and test Datasets into DataLoaders\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=32, # how many samples per batch\n",
    "    num_workers=os.cpu_count(), # how many subprocesses to use for data loading? (higher = more)\n",
    "    shuffle=True # Shuffle the data?\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=32, # how many samples per batch\n",
    "    num_workers=os.cpu_count(), # how many subprocesses to use for data loading? (higher = more)\n",
    "    shuffle=False # don´t usually need to shuffle testing data \n",
    ")\n",
    "\n",
    "train_dataloader, test_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = next(iter(train_dataloader))\n",
    "\n",
    "print(f\"Image shape: {img.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Option 2: Loading Image Data with Custom `Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instances of torchvision.datasets.ImageFolder\n",
    "train_data.classes, train_data.class_to_idx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 Creating a helper function to get class names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup path for target directory\n",
    "target_directory = train_dir\n",
    "print(f'Target directory: {target_directory}')\n",
    "\n",
    "# Get the class names from the target directory\n",
    "class_names_found = sorted([entry.name for entry in list(os.scandir(image_path/\"train\"))])\n",
    "print(f'Class anmes found : {class_names_found}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make function to find classes in target directory\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\n",
    "    \n",
    "    Assumes target directory is in standard image classification format.\n",
    "\n",
    "    Args:\n",
    "        directory (str): target directory to load classnames from.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[List[str], Dict[str, int]]: (list_of_class_names, dict(class_name: idx...))\n",
    "    \n",
    "    Example:\n",
    "        find_classes(\"food_images/train\") >>> ([\"class_1\", \"class_2\"], {\"class_1\": 0, ...})\n",
    "    \"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "    # 2. Raise an error if class names not found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f'Could not find any classes in {directory}.')\n",
    "\n",
    "    # 3. Create a dictionary of index labels (computers prefer numerical rather than string labels)\n",
    "    class_to_idx = {cls_name: i for i, cls_name in enumerate(classes)}\n",
    "    return classes, class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_classes(train_dir)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2 Create a custom `Dataset` to replicate `ImageFolder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a custom dataset class (inherits from torch.utils.data.Dataset)\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "\n",
    "    # 2. Initialize with a targ_dir and transform (optional) parameter\n",
    "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # 3. Create class attributes\n",
    "        # Get all image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob('*/*.jpg')) # note: you'd have to update this if you've got png's or jpeg's\n",
    "\n",
    "        # Set transforms\n",
    "        self.transform = transform\n",
    "\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Make function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    # 5. Overwrite the __len__() methos (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name # expects path in data_folder/class_name/image.jpg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return data, label (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment train data\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# Don't augment test data, only reshape\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((64,64)),\n",
    "    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_dataset = ImageFolderCustom(train_dir, train_transforms)\n",
    "test_custom_dataset = ImageFolderCustom(test_dir, test_transforms)\n",
    "\n",
    "train_custom_dataset, test_custom_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_custom_dataset), len(test_custom_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_custom_dataset.classes, train_custom_dataset.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_custom_dataset) == len(train_data), train_custom_dataset.classes == train_data.classes, train_custom_dataset.class_to_idx == train_data.class_to_idx "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Create a function to display random images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Take in a Dataset as well as a list of class names\n",
    "def display_random_images(dataset: torch.utils.data.dataset.Dataset,\n",
    "                          classes: List[str] = None,\n",
    "                          n: int = 10,\n",
    "                          display_shape: bool = True,\n",
    "                          seed: int = None):\n",
    "    \n",
    "    # 2. Adjust display if n too high\n",
    "    if n > 10:\n",
    "        n = 10\n",
    "        display_shape = False\n",
    "        print(f\"For display purposes, n shouldn't be larger than 10, setting to 10 and removing shape display.\")\n",
    "    \n",
    "    # 3. Set random seed\n",
    "    if seed:\n",
    "        random.seed(seed)\n",
    "\n",
    "    # 4. Get random sample indexes\n",
    "    random_sample_indexes = random.sample(range(len(dataset)), k=n)\n",
    "\n",
    "    # 5. Setup plot\n",
    "    plt.figure(figsize=(16,8))\n",
    "\n",
    "    # 6. Loop through samples and display random samples\n",
    "    for i, targ_sample in enumerate(random_sample_indexes):\n",
    "\n",
    "        targ_img, targ_label = dataset[targ_sample][0], dataset[targ_sample][1]\n",
    "\n",
    "        # 7. Adjust image tensor shape for plotting: [color_channels, height, width] -> [height, width, color_channels]\n",
    "        targ_img = targ_img.permute(1,2,0)\n",
    "\n",
    "        # 8. Plot adjusted images\n",
    "        plt.subplot(1, n, i+1)\n",
    "        plt.imshow(targ_img)\n",
    "        plt.axis(False)\n",
    "        if classes:\n",
    "            title = f\"class: {classes[targ_label]}\"\n",
    "            if display_shape:\n",
    "                title = title + f\"\\nshape: {targ_img.shape}\"\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(train_data, classes=class_names, n=5, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_random_images(train_custom_dataset, classes=class_names, n=5, seed=42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Turn custom loaded images into `DataLoader`'s  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn train and test custom Dataset's into DataLoader's\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader_custom = DataLoader(dataset=train_custom_dataset, # use custom created train Dataset\n",
    "                                     batch_size=1, # how many samples per batch?\n",
    "                                     num_workers=0, # how many subprocesses to use for data loading? (higher = more)\n",
    "                                     shuffle=True) # shuffle the data?\n",
    "\n",
    "test_dataloader_custom = DataLoader(dataset=test_custom_dataset, # use custom created test Dataset\n",
    "                                    batch_size=1, \n",
    "                                    num_workers=0, \n",
    "                                    shuffle=False) # don't usually need to shuffle testing data\n",
    "\n",
    "train_dataloader_custom, test_dataloader_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image and label from custom DataLoader\n",
    "img_custom, label_custom = next(iter(train_dataloader_custom))\n",
    "\n",
    "# Batch size will now be 1, try changing the batch_size parameter above and see what happens\n",
    "print(f\"Image shape: {img_custom.shape} -> [batch_size, color_channels, height, width]\")\n",
    "print(f\"Label shape: {label_custom.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiteacher",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645d004dd1412f554783dad564b4ed89d297d59ce6765071e5ea4608253deff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
