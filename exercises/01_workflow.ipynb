{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create a straight line dataset using the linear regression formula (weight * X + bias)\n",
    "- Set `weight=0.3` and `bias=0.9` there should be at least 100 datapoints total\n",
    "- Split the data into 80% training, 20% testing\n",
    "- Plot the training and testing data so it becomes visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight, bias = 0.3, 0.9\n",
    "start, end, step = -1, 1, 0.02\n",
    "\n",
    "X = torch.arange(start, end, step).unsqueeze(dim=1)\n",
    "y = weight * X + bias\n",
    "\n",
    "print(f\"Number of X samples: {len(X)}\")\n",
    "print(f\"Number of y samples: {len(y)}\")\n",
    "\n",
    "split_training = int(0.8 * len(X))\n",
    "X_train, X_test = X[:split_training], X[split_training:]\n",
    "y_train, y_test = y[:split_training], y[split_training:]\n",
    "len(X_train), len(y_train), len(X_test), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(train_data, train_labels, test_data, test_labels, predictions=None):\n",
    "    \"\"\"\n",
    "    Plot training data, test data and compares predictions\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(5,3))\n",
    "\n",
    "    # Plot training data in blue\n",
    "    plt.scatter(train_data, train_labels, c='b', s=4, label=\"Training data\")\n",
    "\n",
    "    # Plot test data in green\n",
    "    plt.scatter(test_data, test_labels, c='g', s=4, label='Testing data')\n",
    "\n",
    "    if predictions is not None:\n",
    "        # Plot the predictions in red (predictions were made on the test data)\n",
    "        plt.scatter(test_data, predictions, c='r', s=4, label='predictions')\n",
    "\n",
    "    # Show the legend\n",
    "    plt.legend(prop={'size': 14})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_predictions(X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Build a PyTorch model by subclassing `nn.Module`\n",
    "- Inside should be a randomly initialized `nn.Parameter()` with `requires_grad=True`, one for `weights` and one for `bias`\n",
    "- Implement the `forward()` method to compute the linear regression function you used to create the dataset in 1.\n",
    "- Once you've constructed the model, make an instance of it and check its `state_dict()`.\n",
    "- **Note** if you'd like to use `nn.Linear()` instead of `nn.Parameter()` you can."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.linear_layer = nn.Linear(in_features=1, out_features=1, device=device, dtype=torch.float32)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.linear_layer(X)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "model = LinearRegressionModel()\n",
    "model.state_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a loss function and optimizer using `nn.L1Loss()` and `torch.optim.SGD(params, lr)` respectively\n",
    "- Set the learning rate of the optimizer to be 0.01 and the parameters to optimize should be the model parameters from the model you created in 2.\n",
    "- Write a training loop to perform the appropriate training steps for 300 epochs.\n",
    "- The training loop should test the model on the test dataset every 20 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.L1Loss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "X_train, X_test = X_train.to(device), X_test.to(device)\n",
    "y_train, y_test = y_train.to(device), y_test.to(device)\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    ## Training\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    # 1. Forward pass\n",
    "    train_preds = model(X_train)\n",
    "\n",
    "    # 2. Calculate loss\n",
    "    train_loss = loss_fn(train_preds, y_train)\n",
    "\n",
    "    # 3. Zero grad\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # 4. Loss backward\n",
    "    train_loss.backward()\n",
    "\n",
    "    # 5. Progress the optimizer\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 20 == 0:\n",
    "    ## Test\n",
    "\n",
    "        # put model in eval mode\n",
    "        model.eval()\n",
    "\n",
    "        with torch.inference_mode():\n",
    "\n",
    "            # 1. Forward pass\n",
    "            test_preds = model(X_test)\n",
    "\n",
    "            # 2. Calculate loss\n",
    "            test_loss = loss_fn(test_preds, y_test)\n",
    "\n",
    "            print(f'epoch: {epoch} | train loss: {train_loss:.3f} | test loss: {test_loss:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make predictions with the trained model on the test data\n",
    "- Visualize these predictions against the original training and testing data\n",
    "(**note**: you may need to make sure the predictions are *not* on the GPU if you want to use non-CUDA-enabled libraries such as matplotlib to plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.inference_mode():\n",
    "    y_preds = model(X_test)\n",
    "\n",
    "plot_predictions(X_train.cpu(), y_train.cpu(), X_test.cpu(), y_test.cpu(), y_preds.cpu())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Save your trained model's `state_dict()` to file\n",
    "- Create a new instance of your model class you made in 2, and load in the `state_dict()` you just saved to it.\n",
    "- Perform predictions on your test data with the loaded model and confirm they match the original model predictions from 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# 1. Create models dir\n",
    "MODEL_PATH = Path('models')\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 2. Create model save path\n",
    "MODEL_NAME = '01_pytorch_workflow_model_0.pth'\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n",
    "\n",
    "# 3. Save the model state dict\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = LinearRegressionModel()\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "\n",
    "loaded_model.eval()\n",
    "with torch.inference_mode():\n",
    "    loaded_preds = loaded_model(X_test)\n",
    "\n",
    "test_preds == loaded_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('aiteacher')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 11:38:47) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "645d004dd1412f554783dad564b4ed89d297d59ce6765071e5ea4608253deff6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
